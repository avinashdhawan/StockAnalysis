{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1997-05-15 00:00:00'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from website\n",
    "ts = int(863654400)\n",
    "date_found = dt.datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "date_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591488000.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the start date in unix time\n",
    "# HTTP request asks for this\n",
    "d = dt.date(2020,6,6)\n",
    "\n",
    "# it appears (there is a 2 hour timezone difference)\n",
    "unixtime_start = time.mktime(d.timetuple()) + 72000\n",
    "unixtime_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863654400.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the end date in unix time\n",
    "# HTTP request asks for this\n",
    "d = dt.date(1997,5,14)\n",
    "\n",
    "# it appears (there is a 2 hour timezone difference)\n",
    "unixtime_end = time.mktime(d.timetuple()) + 72000\n",
    "unixtime_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-39462f1a798a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# to call browser.quit() at the end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# instead Python will manage that for me :)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mBrowser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chrome'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# URL creation for HTTP request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mstock_ticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"AMZN\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Browser' is not defined"
     ]
    }
   ],
   "source": [
    "# check you version of chrome browser\n",
    "# use the compatible chromedriver.exe\n",
    "# mine is 'ChromeDriver 83.0.4103.39'\n",
    "# 'https://chromedriver.chromium.org/downloads'\n",
    "executable_path = {'executable_path':'./chromedriver.exe'}\n",
    "\n",
    "# use Python context manager (with) so I do not need\n",
    "# to call browser.quit() at the end\n",
    "# instead Python will manage that for me :)\n",
    "with Browser('chrome', **executable_path) as browser:\n",
    "    # URL creation for HTTP request\n",
    "    stock_ticker = \"AMZN\"\n",
    "    tab_selection = \"history\"\n",
    "    period2 = int(unixtime_start)\n",
    "    period1 = int(unixtime_end)\n",
    "    interval = \"1d\"\n",
    "    filter_stocks = \"history&frequency=1d\"\n",
    "    # custom URL\n",
    "    # 'https://ca.finance.yahoo.com/quote/AMZN/history?period1=863654400&period2=1591488000&interval=1d&filter=history&frequency=1d'\n",
    "    url = (\n",
    "           f\"https://ca.finance.yahoo.com/quote/\" +\n",
    "           f\"{stock_ticker}/{tab_selection}?period1={period1}\" +\n",
    "           f\"&period2={period2}&interval={interval}&\" +\n",
    "           f\"filter={filter_stocks}\"\n",
    "           )\n",
    "    # visit the url\n",
    "    browser.visit(url)\n",
    "    # sleep on the page for a couple of seconds cause it is\n",
    "    # resource intensive\n",
    "    time.sleep(6)\n",
    "    # this while loop will scroll through the infinitely scrolling\n",
    "    # element\n",
    "    # this will allow for the HTML table (that is dynamically generated)\n",
    "    # to be in the HTML\n",
    "    # get the current height of the <div id=render-target-default>\n",
    "    lastHeight = browser.execute_script(r\"return document.querySelector('#render-target-default').scrollHeight\")\n",
    "    while True:\n",
    "        # scroll to the bottom of the div\n",
    "        browser.execute_script(\"window.scrollTo(0, document.querySelector('#render-target-default').scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "        # check for the new height of the div\n",
    "        newHeight = browser.execute_script(\"return document.querySelector('#render-target-default').scrollHeight\")\n",
    "        # if the new height and the last height are the same\n",
    "        # then shut down the while loop\n",
    "        if newHeight == lastHeight:\n",
    "            break\n",
    "        # set the last Height to the new height and iterate again\n",
    "        lastHeight = newHeight\n",
    "        \n",
    "    # use pandas.read_html() to get the html table as a\n",
    "    # pandas dataframe\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    df_list = pd.read_html(html)\n",
    "    df = df_list[0]\n",
    "\n",
    "# show some data that was scraped from the HTML table\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
